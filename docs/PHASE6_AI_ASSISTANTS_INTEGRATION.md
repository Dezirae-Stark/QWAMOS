# QWAMOS Phase 6 - AI Assistants Integration

## Overview

Integration of three AI assistants into QWAMOS as optional, privacy-focused services that can be toggled on/off via UI and CLI.

**Date:** 2025-11-03
**Status:** Phase 6 @ 0% ‚Üí 30%
**Integration Type:** Optional services with local/cloud hybrid architecture

---

## Three AI Assistants

### 1. Kali GPT (Local LLM - Pentesting)
**Purpose:** On-device AI pentesting assistant
**Model:** Llama 3.1 8B (quantized for mobile)
**Privacy:** 100% local, no cloud dependency
**Use Cases:**
- Security testing guidance
- CVE database queries
- Exploit suggestions
- Tool automation (nmap, sqlmap, metasploit, burpsuite)
- Report generation

### 2. Claude (Anthropic API - General Purpose)
**Purpose:** Advanced reasoning and coding assistant
**Model:** Claude 3.5 Sonnet (API)
**Privacy:** Cloud-based, encrypted API calls via Tor
**Use Cases:**
- Complex problem solving
- Code analysis and generation
- System architecture design
- Technical documentation
- Long-form reasoning tasks

### 3. ChatGPT (OpenAI API - General Purpose)
**Purpose:** Versatile AI assistant
**Model:** GPT-4 Turbo (API)
**Privacy:** Cloud-based, encrypted API calls via Tor
**Use Cases:**
- General assistance
- Quick Q&A
- Text generation
- Summarization
- Creative tasks

---

## Architecture

### Directory Structure

```
ai/
‚îú‚îÄ‚îÄ kali_gpt/                      # Local LLM
‚îÇ   ‚îú‚îÄ‚îÄ kali_gpt_controller.py     # Llama controller
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Model files (4-8GB)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llama-3.1-8b-q4.gguf  # Quantized model
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                   # System prompts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pentesting.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cve_lookup.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tool_usage.txt
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # Tool integrations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nmap_integration.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sqlmap_integration.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metasploit_integration.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ burpsuite_integration.py
‚îÇ   ‚îî‚îÄ‚îÄ knowledge/                 # Knowledge bases
‚îÇ       ‚îú‚îÄ‚îÄ cve_database.json
‚îÇ       ‚îî‚îÄ‚îÄ exploitdb_index.json
‚îú‚îÄ‚îÄ claude/                        # Anthropic Claude
‚îÇ   ‚îú‚îÄ‚îÄ claude_controller.py       # API controller
‚îÇ   ‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ system.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ coding.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analysis.txt
‚îÇ   ‚îî‚îÄ‚îÄ cache/                     # Response cache
‚îÇ       ‚îî‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ chatgpt/                       # OpenAI ChatGPT
‚îÇ   ‚îú‚îÄ‚îÄ chatgpt_controller.py      # API controller
‚îÇ   ‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ system.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ assistant.txt
‚îÇ   ‚îî‚îÄ‚îÄ cache/
‚îÇ       ‚îî‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ ai_manager.py                  # Central AI orchestrator
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ kali_gpt_config.json       # Model settings
‚îÇ   ‚îú‚îÄ‚îÄ claude_config.json         # API settings
‚îÇ   ‚îî‚îÄ‚îÄ chatgpt_config.json        # API settings
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_kali_gpt.py
    ‚îú‚îÄ‚îÄ test_claude.py
    ‚îî‚îÄ‚îÄ test_chatgpt.py
```

---

## Privacy & Security Model

### Network Routing

**Kali GPT (Local):**
```
User ‚Üí QWAMOS ‚Üí Kali GPT (localhost)
‚úÖ No network access
‚úÖ 100% private
‚úÖ No API keys required
```

**Claude/ChatGPT (Cloud):**
```
User ‚Üí QWAMOS ‚Üí Tor/I2P ‚Üí VPN ‚Üí API
‚úÖ Multi-hop anonymization
‚úÖ Encrypted API calls (HTTPS over Tor)
‚úÖ No IP leaks
‚úÖ Optional: Request sanitization
```

### API Key Management

**Storage:** TEE (TrustZone/StrongBox)
```python
# Keys encrypted with Kyber-1024 + ChaCha20
{
  "claude_api_key": "sk-ant-...",  # Encrypted
  "openai_api_key": "sk-proj-...", # Encrypted
  "encryption": "kyber1024+chacha20poly1305"
}
```

**Access Control:**
- Biometric unlock required
- Keys never stored in plaintext
- Auto-lock after 5 minutes idle
- Wipe on panic gesture

---

## Implementation: AI Manager

### File: `ai/ai_manager.py`

**Purpose:** Central orchestrator for all AI services

**Features:**
- Service registration and discovery
- Toggle individual assistants on/off
- Route queries to appropriate assistant
- Context management
- Usage tracking
- Cost monitoring (for API services)

**Key Methods:**
```python
class AIManager:
    def enable_kali_gpt(self)
    def enable_claude(self, api_key: str)
    def enable_chatgpt(self, api_key: str)

    def disable_kali_gpt(self)
    def disable_claude(self)
    def disable_chatgpt(self)

    def query(self, service: str, prompt: str, context: dict)
    def get_status(self) -> dict
    def get_usage_stats(self) -> dict
```

---

## Implementation: Kali GPT (Local LLM)

### File: `ai/kali_gpt/kali_gpt_controller.py`

**Model:** Llama 3.1 8B (4-bit quantized, ~4.5GB)
**Backend:** llama.cpp (optimized for ARM64)

**Features:**
1. **Pentesting Guidance**
   - Scan target analysis
   - Vulnerability assessment
   - Exploit recommendations
   - Post-exploitation strategies

2. **Tool Integration**
   ```python
   # Example: Automated nmap scan analysis
   kali_gpt.analyze_nmap_results("/tmp/scan.xml")

   # Output:
   # - Open ports analysis
   # - Service version vulnerabilities
   # - Recommended exploits
   # - Next steps
   ```

3. **CVE Database**
   - Offline CVE lookup (2020-2025)
   - CVSS score interpretation
   - Patch availability
   - Exploit code links

4. **Report Generation**
   ```python
   kali_gpt.generate_report({
       "target": "192.168.1.100",
       "scans": [...],
       "findings": [...],
       "recommendations": [...]
   })
   ```

**Performance:**
- Inference speed: ~10 tokens/sec (ARM64)
- Memory usage: 5-6GB RAM
- Cold start: ~5 seconds
- Warm inference: ~500ms per query

---

## Implementation: Claude Integration

### File: `ai/claude/claude_controller.py`

**API:** Anthropic Claude 3.5 Sonnet
**Endpoint:** https://api.anthropic.com/v1/messages

**Features:**
1. **Advanced Reasoning**
   - Complex problem decomposition
   - Multi-step analysis
   - Code review and generation
   - System design

2. **Privacy-Enhanced Requests**
   ```python
   # Route through Tor
   session = requests.Session()
   session.proxies = {
       'http': 'socks5h://127.0.0.1:9050',
       'https': 'socks5h://127.0.0.1:9050'
   }

   # Optional: Sanitize requests
   sanitized_prompt = remove_pii(user_prompt)

   response = claude.query(sanitized_prompt)
   ```

3. **Context Management**
   - Conversation history (local storage)
   - System prompts for QWAMOS context
   - Token usage tracking
   - Cost estimation

4. **Streaming Responses**
   ```python
   for chunk in claude.stream_query(prompt):
       print(chunk, end='', flush=True)
   ```

**API Configuration:**
```json
{
  "model": "claude-3-5-sonnet-20241022",
  "max_tokens": 4096,
  "temperature": 0.7,
  "routing": "tor",
  "cache_responses": true,
  "sanitize_requests": true
}
```

---

## Implementation: ChatGPT Integration

### File: `ai/chatgpt/chatgpt_controller.py`

**API:** OpenAI GPT-4 Turbo
**Endpoint:** https://api.openai.com/v1/chat/completions

**Features:**
1. **Versatile Assistance**
   - Quick answers
   - Code snippets
   - Explanations
   - Brainstorming

2. **Function Calling**
   ```python
   # Example: Execute terminal commands
   chatgpt.query("Run nmap scan on 192.168.1.1",
                 functions=[execute_command])

   # ChatGPT responds with function call:
   # execute_command("nmap -sV 192.168.1.1")
   ```

3. **Image Analysis** (GPT-4 Vision)
   ```python
   # Analyze screenshots
   chatgpt.analyze_image("/sdcard/screenshot.png",
                         "What vulnerabilities do you see?")
   ```

4. **Code Interpreter**
   - Python code execution in sandbox
   - Data analysis
   - Visualization generation

**API Configuration:**
```json
{
  "model": "gpt-4-turbo-preview",
  "max_tokens": 4096,
  "temperature": 0.7,
  "routing": "tor",
  "functions": ["execute_command", "read_file", "analyze_scan"]
}
```

---

## CLI Interface

### Command: `qwamos-ai`

**Usage:**
```bash
# Enable/disable services
qwamos-ai enable kali-gpt
qwamos-ai enable claude --api-key sk-ant-...
qwamos-ai enable chatgpt --api-key sk-proj-...

qwamos-ai disable kali-gpt
qwamos-ai disable claude
qwamos-ai disable chatgpt

# Check status
qwamos-ai status
# Output:
# Kali GPT:  ‚úÖ Enabled (local)
# Claude:    ‚úÖ Enabled (API, Tor routing)
# ChatGPT:   ‚ùå Disabled

# Query assistants
qwamos-ai query kali-gpt "Analyze nmap scan results"
qwamos-ai query claude "Explain this code: $(cat script.py)"
qwamos-ai query chatgpt "Summarize this log file"

# Interactive mode
qwamos-ai chat kali-gpt
qwamos-ai chat claude
qwamos-ai chat chatgpt

# Usage stats
qwamos-ai stats
# Output:
# Kali GPT:  150 queries, 0 cost
# Claude:    45 queries, $2.35
# ChatGPT:   30 queries, $1.80
```

---

## React Native UI Integration

### New Screens

**1. AI Assistants Screen** (`ui/screens/AIAssistants.tsx`)

```typescript
interface AIAssistantsScreenProps {}

const AIAssistantsScreen: React.FC<AIAssistantsScreenProps> = () => {
  return (
    <View style={styles.container}>
      <Text style={styles.title}>AI Assistants</Text>

      {/* Kali GPT Card */}
      <AIServiceCard
        name="Kali GPT"
        description="Local pentesting assistant"
        icon="shield-lock"
        status={kaliGptStatus}
        onToggle={toggleKaliGpt}
        privacy="üü¢ 100% Local"
      />

      {/* Claude Card */}
      <AIServiceCard
        name="Claude"
        description="Advanced reasoning assistant"
        icon="brain"
        status={claudeStatus}
        onToggle={toggleClaude}
        privacy="üü° Cloud via Tor"
        requiresApiKey={true}
      />

      {/* ChatGPT Card */}
      <AIServiceCard
        name="ChatGPT"
        description="General purpose assistant"
        icon="comment-dots"
        status={chatGptStatus}
        onToggle={toggleChatGpt}
        privacy="üü° Cloud via Tor"
        requiresApiKey={true}
      />

      {/* Usage Stats */}
      <UsageStatsCard stats={usageStats} />
    </View>
  );
};
```

**2. AI Chat Screen** (`ui/screens/AIChat.tsx`)

```typescript
interface AIChatScreenProps {
  service: 'kali-gpt' | 'claude' | 'chatgpt';
}

const AIChatScreen: React.FC<AIChatScreenProps> = ({ service }) => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');

  const sendMessage = async () => {
    const response = await AIManager.query(service, input);
    setMessages([...messages,
      { role: 'user', content: input },
      { role: 'assistant', content: response }
    ]);
  };

  return (
    <View style={styles.container}>
      <ChatHeader service={service} />
      <MessageList messages={messages} />
      <ChatInput
        value={input}
        onChangeText={setInput}
        onSend={sendMessage}
      />
    </View>
  );
};
```

### UI Components

**1. AIServiceCard** (`ui/components/AIServiceCard.tsx`)
- Service name and icon
- Status indicator (enabled/disabled)
- Toggle switch
- Privacy level badge
- "Open Chat" button
- API key input (if required)

**2. ChatMessage** (`ui/components/ChatMessage.tsx`)
- User/assistant differentiation
- Markdown rendering
- Code syntax highlighting
- Copy to clipboard
- Timestamp

**3. UsageStatsCard** (`ui/components/UsageStatsCard.tsx`)
- Query counts per service
- API costs (Claude, ChatGPT)
- Token usage
- Response time averages

---

## Configuration Files

### `ai/config/kali_gpt_config.json`

```json
{
  "model_path": "/opt/qwamos/ai/kali_gpt/models/llama-3.1-8b-q4.gguf",
  "context_length": 8192,
  "temperature": 0.7,
  "top_p": 0.9,
  "threads": 4,
  "gpu_layers": 0,
  "system_prompt": "You are Kali GPT, an expert penetration testing assistant...",
  "tools": [
    "nmap",
    "sqlmap",
    "metasploit",
    "burpsuite",
    "nikto",
    "gobuster"
  ],
  "knowledge_bases": [
    "cve_database",
    "exploitdb"
  ]
}
```

### `ai/config/claude_config.json`

```json
{
  "api_endpoint": "https://api.anthropic.com/v1/messages",
  "model": "claude-3-5-sonnet-20241022",
  "max_tokens": 4096,
  "temperature": 0.7,
  "routing": {
    "method": "tor",
    "proxy": "socks5h://127.0.0.1:9050",
    "verify_ssl": true
  },
  "privacy": {
    "sanitize_requests": true,
    "cache_locally": true,
    "log_queries": false
  },
  "cost_limits": {
    "max_monthly_cost": 50.00,
    "alert_threshold": 40.00
  }
}
```

### `ai/config/chatgpt_config.json`

```json
{
  "api_endpoint": "https://api.openai.com/v1/chat/completions",
  "model": "gpt-4-turbo-preview",
  "max_tokens": 4096,
  "temperature": 0.7,
  "routing": {
    "method": "tor",
    "proxy": "socks5h://127.0.0.1:9050",
    "verify_ssl": true
  },
  "features": {
    "function_calling": true,
    "vision": true,
    "code_interpreter": false
  },
  "cost_limits": {
    "max_monthly_cost": 50.00,
    "alert_threshold": 40.00
  }
}
```

---

## Security Considerations

### 1. API Key Protection
- ‚úÖ Stored in TEE (TrustZone/StrongBox)
- ‚úÖ Encrypted with Kyber-1024 + ChaCha20
- ‚úÖ Require biometric unlock
- ‚úÖ Auto-wipe on panic gesture
- ‚úÖ Never logged or cached

### 2. Request Sanitization
```python
def sanitize_request(prompt: str) -> str:
    """Remove PII and sensitive data from prompts"""
    # Remove IP addresses
    prompt = re.sub(r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b',
                    '[IP_REDACTED]', prompt)

    # Remove API keys
    prompt = re.sub(r'sk-[a-zA-Z0-9]{48}', '[API_KEY]', prompt)

    # Remove email addresses
    prompt = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
                    '[EMAIL]', prompt)

    # Remove phone numbers
    prompt = re.sub(r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',
                    '[PHONE]', prompt)

    return prompt
```

### 3. Network Isolation
- ‚úÖ Claude/ChatGPT only accessible via Tor
- ‚úÖ Kali GPT has no network access
- ‚úÖ DNS over Tor for API resolution
- ‚úÖ Kill switch prevents API leaks

### 4. Response Validation
```python
def validate_response(response: dict) -> bool:
    """Ensure API responses are safe"""
    # Check for malicious code injection
    if contains_suspicious_patterns(response['content']):
        return False

    # Verify response signature (if available)
    if not verify_response_integrity(response):
        return False

    return True
```

---

## Installation & Setup

### 1. Install Kali GPT (Local)

```bash
# Download Llama 3.1 8B model (4.5GB)
cd ~/QWAMOS/ai/kali_gpt/models
wget https://huggingface.co/TheBloke/Llama-3.1-8B-GGUF/resolve/main/llama-3.1-8b.Q4_K_M.gguf

# Install llama.cpp
pkg install clang cmake
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
cmake -B build -DCMAKE_BUILD_TYPE=Release
cmake --build build

# Test model
./build/bin/main -m ../ai/kali_gpt/models/llama-3.1-8b.Q4_K_M.gguf \
                 -p "You are a pentesting assistant. Explain SQL injection." \
                 -n 128
```

### 2. Configure Claude

```bash
# Set API key (encrypted storage)
qwamos-ai enable claude --api-key sk-ant-api03-YOUR_KEY_HERE

# Test connection
qwamos-ai query claude "Hello, can you hear me?"
```

### 3. Configure ChatGPT

```bash
# Set API key
qwamos-ai enable chatgpt --api-key sk-proj-YOUR_KEY_HERE

# Test connection
qwamos-ai query chatgpt "Hello, test message"
```

---

## Testing

### Test 1: Kali GPT Inference
```bash
cd ~/QWAMOS/ai/tests
python3 test_kali_gpt.py
```

**Expected:**
```
‚úÖ Model loaded successfully (4.5GB)
‚úÖ Inference test passed (10 tokens/sec)
‚úÖ CVE lookup functional
‚úÖ Tool integration working
‚úÖ Memory usage acceptable (5.8GB)
```

### Test 2: Claude API
```bash
python3 test_claude.py
```

**Expected:**
```
‚úÖ API key validated
‚úÖ Tor routing active
‚úÖ Request successful (200 OK)
‚úÖ Response received (1.2s latency)
‚úÖ Token usage: 250 tokens
‚úÖ Cost: $0.0025
```

### Test 3: ChatGPT API
```bash
python3 test_chatgpt.py
```

**Expected:**
```
‚úÖ API key validated
‚úÖ Tor routing active
‚úÖ Request successful (200 OK)
‚úÖ Response received (0.9s latency)
‚úÖ Function calling enabled
‚úÖ Token usage: 180 tokens
‚úÖ Cost: $0.0018
```

---

## Performance Benchmarks

### Kali GPT (Local)
| Metric | Value |
|--------|-------|
| Cold start | 5 seconds |
| Inference speed | 10 tokens/sec |
| Memory usage | 5.8 GB RAM |
| Storage | 4.5 GB |
| Latency | ~500ms |
| Cost | $0 (free) |

### Claude (API)
| Metric | Value |
|--------|-------|
| Latency (via Tor) | 1-2 seconds |
| Token cost (input) | $0.003 / 1K |
| Token cost (output) | $0.015 / 1K |
| Max context | 200K tokens |
| Rate limit | 50 req/min |

### ChatGPT (API)
| Metric | Value |
|--------|-------|
| Latency (via Tor) | 0.8-1.5 seconds |
| Token cost (input) | $0.01 / 1K |
| Token cost (output) | $0.03 / 1K |
| Max context | 128K tokens |
| Rate limit | 10K req/min |

---

## Cost Estimation

### Monthly Usage Example

**Moderate User:**
- Kali GPT: 200 queries/month = $0
- Claude: 100 queries/month (~50K tokens) = $2.25
- ChatGPT: 50 queries/month (~25K tokens) = $1.25
- **Total: ~$3.50/month**

**Heavy User:**
- Kali GPT: 1000 queries/month = $0
- Claude: 500 queries/month (~250K tokens) = $11.25
- ChatGPT: 300 queries/month (~150K tokens) = $7.50
- **Total: ~$18.75/month**

---

## Timeline

### Phase 6a: AI Infrastructure (Week 1-2)
- Day 1-2: Create ai/ directory structure
- Day 3-4: Implement AIManager orchestrator
- Day 5-7: Kali GPT controller + llama.cpp integration
- Day 8-10: Claude controller + Tor routing
- Day 11-12: ChatGPT controller
- Day 13-14: Testing and bug fixes

### Phase 6b: UI Integration (Week 3)
- Day 15-16: AI Assistants screen
- Day 17-18: AI Chat screen
- Day 19-20: UI components (cards, messages)
- Day 21: Integration testing

### Phase 6c: Polish & Documentation (Week 4)
- Day 22-23: Performance optimization
- Day 24-25: Security hardening
- Day 26-27: User documentation
- Day 28: Final testing

**Total Estimated Time:** 4 weeks

---

## Success Criteria

‚úÖ Kali GPT runs locally with <10s cold start
‚úÖ Claude API calls route through Tor successfully
‚úÖ ChatGPT API calls route through Tor successfully
‚úÖ API keys stored securely in TEE
‚úÖ No IP leaks during API calls
‚úÖ UI allows toggling services on/off
‚úÖ CLI interface functional
‚úÖ Request sanitization working
‚úÖ Cost tracking accurate
‚úÖ All tests passing

---

## Future Enhancements

1. **Multi-Model Support**
   - Add Mistral, Gemini, LLaMA 3.2
   - Model switching within same assistant

2. **Voice Interface**
   - Speech-to-text input
   - Text-to-speech output
   - Conversation mode

3. **Context Sharing**
   - Share context between assistants
   - Collaborative problem solving

4. **Custom Fine-Tuning**
   - Fine-tune Kali GPT on user's pentest reports
   - Personalized responses

5. **Offline Mode**
   - Download Claude/GPT responses for offline viewing
   - Pre-cache common queries

---

**Document Version:** 1.0
**Status:** Draft
**Phase:** 6 @ 0% ‚Üí 30% (with implementation)
**Last Updated:** 2025-11-03
